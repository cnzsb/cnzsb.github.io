<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>Node 爬虫实践 - Gitlab 文件下载 | 奔跑的Q丶</title>

  
  <meta name="author" content="赵世博">
  

  
  <meta name="description" content="主题凑合用，样式即将改版...">
  

  
  
  <meta name="keywords" content="Node,Crawler">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="Node 爬虫实践 - Gitlab 文件下载">

  <meta property="og:site_name" content="奔跑的Q丶">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="奔跑的Q丶" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">
          <img src="/avatar.png" alt="avatar">
          奔跑的Q丶
      </a>
    </h1>
    <p class="site-description">主题凑合用，样式即将改版...</p>
    <div class="site-navigation contact-me">
        <ul>
          
            <li><a class="icon-github" href="https://github.com/cnzsb" target="_blank"></a></li>
          
            <li><a class="icon-weibo" href="https://weibo.com/u/2821242461" target="_blank"></a></li>
          
            <li><a class="icon-mail" href="mailto:cnzsb@foxmail.com" target="_blank"></a></li>
          
            <li><a class="icon-rss" href="/atom.xml" target="_blank"></a></li>
          
        </ul>
    </div>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives">归档</a></li>
      
        <li><a href="https://cnzsb.github.io/mydemo">Demo</a></li>
      
    </ul>
  </nav>
</header>


    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>Node 爬虫实践 - Gitlab 文件下载</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/blog/2017/08/28/Node 爬虫实践 - Gitlab 文件下载/" rel="bookmark">
        <time class="entry-date published" datetime="2017-08-28T10:28:26.000Z">
          2017-08-28
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>公司的设计图稿等全部存在 Gitlab 上的某个仓库中，恰好某次迭代需要使用到其中的图稿，因为历史图稿使这个仓库异常大，而我只需要其中很小的一部分，就不想 <code>clone</code> 整个仓库而只想下载需要的文件夹。但是在使用 Git 时如果只想下载其中部分的文件夹是一件很复杂的事情，尝试了各种指令后发现无论如何都要先 <code>fetch</code> 整个项目，而下载其中的一个文件却是一件简单的事情，那不如就动手写个爬虫吧。于是就有了这个项目 <a href="https://github.com/cnzsb/gitlab-fileDownloader" target="_blank" rel="noopener">gitlab-fileDownload</a>：</p>
<img src="/blog/2017/08/28/Node%20爬虫实践%20-%20Gitlab%20文件下载/gitlab-fileDownloader.gif" class="demo-gitlab-fileDownload">

<a id="more"></a>

<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>本项目利用 <code>axios</code> 处理 http 请求，利用 <code>cheerio</code> 解析 <code>HTML</code>。确定用户名、密码等基本配置项：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    url: <span class="string">''</span>,              <span class="comment">// 目标地址</span></span><br><span class="line">    username: <span class="string">''</span>,</span><br><span class="line">    password: <span class="string">''</span>,</span><br><span class="line">    deep: <span class="literal">true</span>,           <span class="comment">// 是否下载文件夹内容</span></span><br><span class="line">    path: <span class="string">'./downloads'</span>,  <span class="comment">// 下载路径</span></span><br><span class="line">    cookie: &#123;             <span class="comment">// 登录后保存的 cookie</span></span><br><span class="line">    value: <span class="string">''</span>,</span><br><span class="line">    expires: <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后设置了模拟真实环境的请求头，并开启 <code>withCredentials</code> 以具备获取 <code>cookie</code> 的能力：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> $http = axios.create(&#123;</span><br><span class="line">    withCredentials: <span class="literal">true</span>,   <span class="comment">// 获取 Cookie</span></span><br><span class="line">    headers: &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'</span>,</span><br><span class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate'</span>,</span><br><span class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8,en;q=0.6,zh-TW;q=0.4'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<h2 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h2><p>首先要处理的就是登录：</p>
<img src="/blog/2017/08/28/Node%20爬虫实践%20-%20Gitlab%20文件下载/gitlab-login.jpg" class="gitlab-login">

<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">const</span> &#123; urlOrigin &#125; = <span class="keyword">this</span>.opts</span><br><span class="line">    <span class="keyword">const</span> urlSignIn = <span class="string">`<span class="subst">$&#123;urlOrigin&#125;</span>/users/sign_in`</span></span><br><span class="line">    <span class="keyword">const</span> resPageSignIn = <span class="keyword">await</span> $http.get(urlSignIn)</span><br><span class="line">    <span class="keyword">this</span>._writeCookie(resPageSignIn.headers)</span><br><span class="line">    <span class="keyword">const</span> $ = cheerio.load(resPageSignIn.data)</span><br><span class="line">    <span class="keyword">const</span> $form = $(<span class="string">'.login-body form'</span>)</span><br><span class="line">    <span class="keyword">const</span> action = $form.attr(<span class="string">'action'</span>)</span><br><span class="line">    <span class="keyword">const</span> method = $form.attr(<span class="string">'method'</span>)</span><br><span class="line">    <span class="keyword">const</span> params = &#123;&#125;</span><br><span class="line">    params.utf8 = $form.find(<span class="string">'[name="utf8"]'</span>).attr(<span class="string">'value'</span>)</span><br><span class="line">    params.authenticity_token = $form.find(<span class="string">'[name="authenticity_token"]'</span>).attr(<span class="string">'value'</span>)</span><br><span class="line">    params.remember_me = <span class="number">1</span>  <span class="comment">// true</span></span><br><span class="line">    params.username = <span class="keyword">this</span>.opts.username</span><br><span class="line">    params.password = <span class="keyword">this</span>.opts.password</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">const</span> reqOpts = &#123;</span><br><span class="line">      maxRedirects: <span class="number">0</span>,</span><br><span class="line">      headers: &#123;</span><br><span class="line">        Cookie: <span class="keyword">this</span>.opts.cookie.value,</span><br><span class="line">        <span class="string">'Content-Type'</span>: <span class="string">'application/x-www-form-urlencoded'</span>,</span><br><span class="line">        <span class="string">'Content-Length'</span>: <span class="built_in">JSON</span>.stringify(params).length</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 302</span></span><br><span class="line">    <span class="keyword">const</span> resLogin = <span class="keyword">await</span> $http[method](<span class="string">`<span class="subst">$&#123;urlOrigin&#125;</span><span class="subst">$&#123;action&#125;</span>`</span>, qs.stringify(params), reqOpts)</span><br><span class="line">    <span class="keyword">this</span>._writeCookie(resLogin.headers)</span><br><span class="line">    <span class="keyword">return</span> resolve()</span><br><span class="line">&#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">    <span class="built_in">console</span>.error(<span class="string">'Error On Page SignIn: '</span>, e)</span><br><span class="line">    <span class="keyword">return</span> reject(e)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>根据页面的表单获取需要发送的元素，并且把获取到的 <code>cookie</code> 使用存起来，以后根据 <code>expires</code> 决定是否需要更新 <code>cookie</code>。这里的登录成功后会返回 302 重定向至目标页面，如果没有处理的话会被当做错误在 <code>catch</code> 中处理，为了方便（偷懒）。在 <code>axios</code> 的初始化设置中增加了 302 为成功。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    validateStatus: <span class="function"><span class="params">status</span> =&gt;</span> (status &gt;= <span class="number">200</span> &amp;&amp; status &lt; <span class="number">300</span> || status === <span class="number">302</span>)  <span class="comment">// gitlab 登录 302 重定向</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="解析页面"><a href="#解析页面" class="headerlink" title="解析页面"></a>解析页面</h2><p>在登录后就需要解析目标页面的数据了，因为可能会遇到文件夹的情况，因此在开始的配置项中增加了 <code>deep</code> 决定是否深度解析文件夹的能力。</p>
<img src="/blog/2017/08/28/Node%20爬虫实践%20-%20Gitlab%20文件下载/gitlab-target-url.jpg" class="gitlab-target-url">

<p>根据页面的结构存储对应资源的名称、下载路径及所在目录地址，根据 <code>deep</code> 决定是否递归：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> $files = $(<span class="string">'.tree-table .tree-item .tree-item-file-name a'</span>)</span><br><span class="line"><span class="keyword">const</span> dicts = []</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; $files.length; i++) &#123;</span><br><span class="line">    <span class="keyword">const</span> $file = $files.eq(i)</span><br><span class="line">    <span class="keyword">const</span> name = $file.attr(<span class="string">'title'</span>)</span><br><span class="line">    <span class="keyword">const</span> url = <span class="string">`<span class="subst">$&#123;<span class="keyword">this</span>.opts.urlOrigin&#125;</span><span class="subst">$&#123;$file.attr(<span class="string">'href'</span>).replace(<span class="string">'/blob/'</span>, <span class="string">'/raw/'</span>)&#125;</span>`</span></span><br><span class="line">    <span class="comment">// 根目录 '..' 没有 name</span></span><br><span class="line">    <span class="keyword">if</span> (!name) <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> (!url.includes(<span class="string">'/raw/'</span>)) &#123;</span><br><span class="line">      <span class="comment">// 同步使结果可控</span></span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">this</span>.opts.deep) dicts.push(...await <span class="keyword">this</span>.getDict(url, <span class="string">`<span class="subst">$&#123;dirname&#125;</span><span class="subst">$&#123;name&#125;</span>/`</span>))</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    dicts.push(&#123; name, url, dirname &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="下载资源"><a href="#下载资源" class="headerlink" title="下载资源"></a>下载资源</h2><p>在获得了所有的资源后便是进行爬取资源并写入硬盘的操作，这里使用了同步下载，因此又是一个递归操作（懒得缓存一个箭头函数并且调用了，因此需要注意 <code>this</code> 的使用）：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">_download(dicts) &#123;</span><br><span class="line"><span class="keyword">const</span> root = <span class="keyword">this</span>.opts.path</span><br><span class="line"><span class="keyword">const</span> count = dicts.length</span><br><span class="line"><span class="keyword">const</span> headers = &#123; <span class="attr">Cookie</span>: <span class="keyword">this</span>.opts.cookie.value &#125;</span><br><span class="line"><span class="keyword">return</span> (<span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">downloadFile</span>(<span class="params">source</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> dirname = <span class="string">`<span class="subst">$&#123;root&#125;</span><span class="subst">$&#123;source.dirname&#125;</span>`</span></span><br><span class="line">    <span class="keyword">if</span> (!fs.existsSync(dirname)) mkdirSync(dirname)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">const</span> &#123; data &#125; = <span class="keyword">await</span> $http.get(source.url, &#123;</span><br><span class="line">        responseType: <span class="string">'stream'</span>,</span><br><span class="line">        headers,</span><br><span class="line">    &#125;)</span><br><span class="line">    data.pipe(fs.createWriteStream(<span class="string">`<span class="subst">$&#123;dirname&#125;</span>/<span class="subst">$&#123;source.name&#125;</span>`</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> (!dicts.length) <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">return</span> downloadFile(dicts.shift())</span><br><span class="line">&#125;)(dicts.shift())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中在保存文件的时候需要检测是否存在文件夹，并且按需进行创建：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">mkdirSync</span>(<span class="params">filepath</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (fs.existsSync(filepath)) <span class="keyword">return</span></span><br><span class="line">    mkdirSync(path.dirname(filepath))</span><br><span class="line">    fs.mkdirSync(filepath)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>随后为了更直观的观测进度又增加了命令行的可视化输出，这一部分及项目的完整代码可以访问 <a href="https://github.com/cnzsb/gitlab-fileDownloader" target="_blank" rel="noopener">Github 仓库</a>查看。</p>
<p>另外思考一个问题，本项目中使用的全部是同步代码，而没有利用异步去处理。其中可以优化的地方就是在解析资源的同时爬取并写入硬盘，但是在变更为异步代码的过程中发现同时发起请求会导致服务器错误，而最小的间隔需要控制在 100ms 左右，当手动控制每 100ms 发起一次请求时却又发现此时的总任务时间慢于同步爬虫，因为受实际网速影响可能下载一个资源会小于 100ms，因此最终没有采用异步的方法。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/Node/">Node</a><a href="/tags/Crawler/">Crawler</a>
    </span>
    

    </div>

    
  </div>
</article>


    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2019 赵世博
    
    
    </br> <a href="https://www.miitbeian.gov.cn/" target="_blank">豫ICP备17044531号-1</a>
    
  </p>
</footer>

    
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-71274501-1', 'auto');
    ga('send', 'pageview');

</script>


  </div>
</div>
</body>
</html>